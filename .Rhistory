}
} else {
effectv = 0
}
var = diag(c(c(1,1),runif(d-2,1-1/2*eq,1+1/2*eq)))
cov = solve(idbmatr) %*% var  %*% t(solve(idbmatr))
data = MASS::mvrnorm(n, mu=rep(0,d), Sigma=cov)
return(list("data"=data,"order"=ord,"effect"=effectv))
}
data=createdatapartial(10,0.5,1000,TRUE)
confDualLRTpartial(data)
# Compute inverse covariance matrix
siginv <- solve((n - 1) / n * stats::cov(data))
data <- data.matrix(data)
n <- nrow(data)
d <- ncol(data)
# Compute inverse covariance matrix
siginv <- solve((n - 1) / n * stats::cov(data))
data
data
dataset=createdatapartial(10,0.5,1000,TRUE)
confDualLRTpartial(dataset$data)
data=dataset$data
data <- data.matrix(data)
n <- nrow(data)
d <- ncol(data)
# Compute inverse covariance matrix
siginv <- solve((n - 1) / n * stats::cov(data, use = 'complete.obs'))
# Approximate MLE by ordering conditional variances
varperm <- which.min(diag(siginv))
val <- diag(siginv)[varperm]
for (i in 1:(d - 1)) {
help <- diag(siginv) - rowSums((siginv[, varperm, drop = FALSE] %*% solve(siginv[varperm, varperm])) * siginv[varperm, , drop = FALSE])
varperm <- c(which.min(help), varperm)
val <- c(help[varperm[1]], val)
}
diag(siginv)
(siginv[, varperm, drop = FALSE]
(siginv[, varperm, drop = FALSE]
siginv[, varperm, drop = FALSE]
siginv[, varperm, drop = FALSE] %*% solve(siginv[varperm, varperm])
siginv[, varperm, drop = FALSE] %*% solve(siginv[varperm, varperm])
(siginv[, varperm, drop = FALSE] %*% solve(siginv[varperm, varperm])) * siginv[varperm, , drop = FALSE])
(siginv[, varperm, drop = FALSE] %*% solve(siginv[varperm, varperm])) * siginv[varperm, , drop = FALSE]
siginv[, varperm, drop = FALSE] %*% solve(siginv[varperm, varperm])
help <- diag(siginv) - rowSums((siginv[, varperm, drop = FALSE] %*% solve(siginv[varperm, varperm])) %*% siginv[varperm, , drop = FALSE])
varperm <- c(which.min(help), varperm)
val <- c(help[varperm[1]], val)
val2=val
varperm=which.min(diag(siginv))
val=diag(siginv)[varperm]
indl=c()
for (i in 1:(d-1)){
help=rep(Inf,d)
for (j in setdiff(1:d,varperm)){
help[j]=siginv[j,j]-siginv[j,varperm]%*%solve(siginv[varperm,varperm])%*%siginv[varperm,j]
}
varperm=c(which.min(help),varperm)
val=c(help[varperm[1]],val)
}
val[which(varperm==1)]
# Approximate MLE by ordering conditional variances
varperm <- which.min(diag(siginv))
val <- diag(siginv)[varperm]
for (i in 1:(d - 1)) {
help <- diag(siginv) - rowSums((siginv[, varperm, drop = FALSE] %*% solve(siginv[varperm, varperm])) %*% siginv[varperm, , drop = FALSE])
varperm <- c(which.min(help), varperm)
val <- c(help[varperm[1]], val)
}
help <- diag(siginv) - rowSums((siginv[, varperm, drop = FALSE] %*% solve(siginv[varperm, varperm])) %*% siginv[varperm, , drop = FALSE])
siginv[, varperm, drop = FALSE]
# Approximate MLE by ordering conditional variances
varperm <- which.min(diag(siginv))
val <- diag(siginv)[varperm]
help <- diag(siginv) - rowSums((siginv[, varperm, drop = FALSE] %*% solve(siginv[varperm, varperm])) %*% siginv[varperm, , drop = FALSE])
varperm <- c(which.min(help), varperm)
varperm=which.min(diag(siginv))
val=diag(siginv)[varperm]
indl=c()
i=1
help=rep(Inf,d)
for (j in setdiff(1:d,varperm)){
help[j]=siginv[j,j]-siginv[j,varperm]%*%solve(siginv[varperm,varperm])%*%siginv[varperm,j]
}
varperm=c(which.min(help),varperm)
# Approximate MLE by ordering conditional variances
varperm <- which.min(diag(siginv))
val <- diag(siginv)[varperm]
help <- diag(siginv) - rowSums((siginv[, varperm, drop = FALSE] %*% solve(siginv[varperm, varperm])) %*% siginv[varperm, , drop = FALSE])
varperm <- c(which.min(help), varperm)
val <- c(help[varperm[1]], val)
# Approximate MLE by ordering conditional variances
varperm <- which.min(diag(siginv))
val <- diag(siginv)[varperm]
for (i in 1:(d-1)){
help <- rep(Inf,d)
for (j in setdiff(1:d,varperm)){
help[j] <- siginv[j,j]-siginv[j,varperm]%*%solve(siginv[varperm,varperm])%*%siginv[varperm,j]
}
varperm <- c(which.min(help),varperm)
val <- c(help[varperm[1]],val)
}
# Approximate threshold for the likelihood ratio test
tresh <- -log((val[which(varperm == 1)] + val[which(varperm == 2)]) * sqrt(prod(val[-which(varperm == 1 | varperm == 2)])))
# Find plausible causal orderings (parallelized)
ordertrue <- parallel::mclapply(0:(3^(d - 2) - 1), orderfuncdualpart, tresh = tresh, d = d, n = n, siginv = siginv, ord = c(1, 2), crit = stats::qchisq(1 - alpha, 2), mc.cores = parallel::detectCores())
ordertrue <- do.call(rbind, ordertrue)
View(ordertrue)
# Find plausible causal orderings (parallelized)
ordertrue <- parallel::mclapply(0:(3^(d - 2) - 1), orderDualLRTpartial, tresh = tresh, d = d, n = n, siginv = siginv, ord = c(1, 2), crit = stats::qchisq(1 - alpha, 2), mc.cores = parallel::detectCores())
ordertrue <- do.call(rbind, ordertrue)
View(ordertrue)
alpha=0.05
# Find plausible causal orderings (parallelized)
ordertrue <- parallel::mclapply(0:(3^(d - 2) - 1), orderDualLRTpartial, tresh = tresh, d = d, n = n, siginv = siginv, ord = c(1, 2), crit = stats::qchisq(1 - alpha, 2), mc.cores = parallel::detectCores())
ordertrue <- do.call(rbind, ordertrue)
View(ordertrue)
index=1
# Convert ordering into partition (before cause, between cause and effect, after effect)
parentset <- unname(gtools::baseOf(index, base = 3, len = d - 2) + 1)
pre <- (3:d)[parentset == 1]
mid <- (3:d)[parentset == 2]
aft <- (3:d)[parentset == 3]
common_inv <- solve(siginv[c(mid, ord[2], aft), c(mid, ord[2], aft)])
ord=c(1,2)
common_inv <- solve(siginv[c(mid, ord[2], aft), c(mid, ord[2], aft)])
val <- siginv[ord[1], ord[1]] - siginv[ord[1], c(mid, ord[2], aft)] %*% common_inv %*% siginv[c(mid, ord[2], aft), ord[1]] + siginv[ord[2], ord[2]]
if (length(aft) != 0) {
val <- val - siginv[ord[2], aft] %*% solve(siginv[aft, aft]) %*% siginv[aft, ord[2]]
}
# Update the likelihood value based on the ordering
update_val <- function(subset, base_set) {
for (i in seq_along(subset)) {
vord <- c(subset[-(1:i)], base_set)
inv_sub <- solve(siginv[vord, vord])
val <<- val * sqrt(siginv[subset[i], subset[i]] - siginv[subset[i], vord] %*% inv_sub %*% siginv[vord, subset[i]])
}
}
if (length(pre) != 0) update_val(pre, c(ord, mid, aft))
if (length(mid) != 0) update_val(mid, c(ord[2], aft))
if (length(aft) != 0) update_val(aft, NULL)
# test the ordering with dual likelihood ratio test
lik <- -log(val)
if ((tresh - lik) > (crit / (2 * n))) {
return()
}
crit=stats::qchisq(1 - alpha, 2)
# test the ordering with dual likelihood ratio test
lik <- -log(val)
if ((tresh - lik) > (crit / (2 * n))) {
return()
}
return(c(pre, ord[1], mid, ord[2], aft, lik))
c(pre, ord[1], mid, ord[2], aft, lik)
#'
#' @param index Integer representing the causal ordering.
#' @param d Number of variables in the system.
#' @param n Sample size.
#' @param siginv Inverse of the covariance matrix.
#' @param tresh Likelihood ratio threshold.
#' @param ord ordering of potential cause and potential effect
#' @param crit Chi-square critical value for hypothesis testing.
#' @return Vector of plausible causal orderings with corresponding likelihood value.
#' @export
orderDualLRTpartial<- function(index, d, n, siginv, tresh, ord, crit) {
# Convert ordering into partition (before cause, between cause and effect, after effect)
parentset <- unname(gtools::baseOf(index, base = 3, len = d - 2) + 1)
pre <- (3:d)[parentset == 1]
mid <- (3:d)[parentset == 2]
aft <- (3:d)[parentset == 3]
common_inv <- solve(siginv[c(mid, ord[2], aft), c(mid, ord[2], aft)])
val <- siginv[ord[1], ord[1]] - siginv[ord[1], c(mid, ord[2], aft)] %*% common_inv %*% siginv[c(mid, ord[2], aft), ord[1]] + siginv[ord[2], ord[2]]
if (length(aft) != 0) {
val <- val - siginv[ord[2], aft] %*% solve(siginv[aft, aft]) %*% siginv[aft, ord[2]]
}
# Update the likelihood value based on the ordering
update_val <- function(subset, base_set) {
for (i in seq_along(subset)) {
vord <- c(subset[-(1:i)], base_set)
inv_sub <- solve(siginv[vord, vord])
val <<- val * sqrt(siginv[subset[i], subset[i]] - siginv[subset[i], vord] %*% inv_sub %*% siginv[vord, subset[i]])
}
}
if (length(pre) != 0) update_val(pre, c(ord, mid, aft))
if (length(mid) != 0) update_val(mid, c(ord[2], aft))
if (length(aft) != 0) update_val(aft, NULL)
# test the ordering with dual likelihood ratio test
lik <- -log(val)
if ((tresh - lik) > (crit / (2 * n))) {
return()
}
return(c(pre, ord[1], mid, ord[2], aft, lik))
}
# Find plausible causal orderings (parallelized)
ordertrue <- parallel::mclapply(0:(3^(d - 2) - 1), orderDualLRTpartial, tresh = tresh, d = d, n = n, siginv = siginv, ord = c(1, 2), crit = stats::qchisq(1 - alpha, 2), mc.cores = parallel::detectCores())
ordertrue <- do.call(rbind, ordertrue)
View(ordertrue)
View(ordertrue)
#outputs orderings
orderfuncdualpart<-function(parentset,d,n,siginv,tresh,ord,crit) {
parentset=unname(baseOf(parentset,base=3,len=d-2)+1)
pre=(3:d)[which(parentset==1)]
mid=(3:d)[which(parentset==2)]
aft=(3:d)[which(parentset==3)]
if(length(aft)!=0) {
val=siginv[ord[1],ord[1]]-siginv[ord[1],c(mid,ord[2],aft)]%*%solve(siginv[c(mid,ord[2],aft),c(mid,ord[2],aft)])%*%siginv[c(mid,ord[2],aft),ord[1]]+siginv[ord[2],ord[2]]-siginv[ord[2],aft]%*%solve(siginv[aft,aft])%*%siginv[aft,ord[2]]
} else {
val=siginv[ord[1],ord[1]]-siginv[ord[1],c(mid,ord[2],aft)]%*%solve(siginv[c(mid,ord[2],aft),c(mid,ord[2],aft)])%*%siginv[c(mid,ord[2],aft),ord[1]]+siginv[ord[2],ord[2]]
}
if (length(pre)!=0){
for (i in 1:length(pre)) {
vord=c(pre[-(1:i)],c(ord,mid,aft))
val=val*sqrt(siginv[pre[i],pre[i]]-siginv[pre[i],vord]%*%solve(siginv[vord,vord])%*%siginv[vord,pre[i]])
}
}
if (length(mid)!=0){
for (i in 1:length(mid)) {
vord=c(mid[-(1:i)],c(ord[2],aft))
val=val*sqrt(siginv[mid[i],mid[i]]-siginv[mid[i],vord]%*%solve(siginv[vord,vord])%*%siginv[vord,mid[i]])
}
}
if (length(aft)!=0){
for (i in 1:length(aft)) {
vord=c(aft[-(1:i)])
if(length(vord)!=0){
val=val*sqrt(siginv[aft[i],aft[i]]-siginv[aft[i],vord]%*%solve(siginv[vord,vord])%*%siginv[vord,aft[i]])
} else {
val=val*sqrt(siginv[aft[i],aft[i]])
}
}
}
lik=-log(val)
if((tresh-lik)>(crit/(2*n))){
return()
}
return(c(pre,ord[1],mid,ord[2],aft,lik))
}
# Find plausible causal orderings (parallelized)
ordertrue <- parallel::mclapply(0:(3^(d - 2) - 1), orderfuncdualpart, tresh = tresh, d = d, n = n, siginv = siginv, ord = c(1, 2), crit = stats::qchisq(1 - alpha, 2), mc.cores = parallel::detectCores())
View(ordertrue)
#outputs orderings
orderfuncdualpart<-function(parentset,d,n,siginv,tresh,ord,crit) {
parentset=unname(gtools::baseOf(parentset,base=3,len=d-2)+1)
pre=(3:d)[which(parentset==1)]
mid=(3:d)[which(parentset==2)]
aft=(3:d)[which(parentset==3)]
if(length(aft)!=0) {
val=siginv[ord[1],ord[1]]-siginv[ord[1],c(mid,ord[2],aft)]%*%solve(siginv[c(mid,ord[2],aft),c(mid,ord[2],aft)])%*%siginv[c(mid,ord[2],aft),ord[1]]+siginv[ord[2],ord[2]]-siginv[ord[2],aft]%*%solve(siginv[aft,aft])%*%siginv[aft,ord[2]]
} else {
val=siginv[ord[1],ord[1]]-siginv[ord[1],c(mid,ord[2],aft)]%*%solve(siginv[c(mid,ord[2],aft),c(mid,ord[2],aft)])%*%siginv[c(mid,ord[2],aft),ord[1]]+siginv[ord[2],ord[2]]
}
if (length(pre)!=0){
for (i in 1:length(pre)) {
vord=c(pre[-(1:i)],c(ord,mid,aft))
val=val*sqrt(siginv[pre[i],pre[i]]-siginv[pre[i],vord]%*%solve(siginv[vord,vord])%*%siginv[vord,pre[i]])
}
}
if (length(mid)!=0){
for (i in 1:length(mid)) {
vord=c(mid[-(1:i)],c(ord[2],aft))
val=val*sqrt(siginv[mid[i],mid[i]]-siginv[mid[i],vord]%*%solve(siginv[vord,vord])%*%siginv[vord,mid[i]])
}
}
if (length(aft)!=0){
for (i in 1:length(aft)) {
vord=c(aft[-(1:i)])
if(length(vord)!=0){
val=val*sqrt(siginv[aft[i],aft[i]]-siginv[aft[i],vord]%*%solve(siginv[vord,vord])%*%siginv[vord,aft[i]])
} else {
val=val*sqrt(siginv[aft[i],aft[i]])
}
}
}
lik=-log(val)
if((tresh-lik)>(crit/(2*n))){
return()
}
return(c(pre,ord[1],mid,ord[2],aft,lik))
}
# Find plausible causal orderings (parallelized)
ordertrue <- parallel::mclapply(0:(3^(d - 2) - 1), orderfuncdualpart, tresh = tresh, d = d, n = n, siginv = siginv, ord = c(1, 2), crit = stats::qchisq(1 - alpha, 2), mc.cores = parallel::detectCores())
ordertrue <- do.call(rbind, ordertrue)
View(ordertrue)
#'
#' @param index Integer representing the causal ordering.
#' @param d Number of variables in the system.
#' @param n Sample size.
#' @param siginv Inverse of the covariance matrix.
#' @param tresh Likelihood ratio threshold.
#' @param ord ordering of potential cause and potential effect
#' @param crit Chi-square critical value for hypothesis testing.
#' @return Vector of plausible causal orderings with corresponding likelihood value.
#' @export
orderDualLRTpartial<- function(index, d, n, siginv, tresh, ord, crit) {
# Convert ordering into partition (before cause, between cause and effect, after effect)
parentset <- unname(gtools::baseOf(index, base = 3, len = d - 2) + 1)
pre <- (3:d)[parentset == 1]
mid <- (3:d)[parentset == 2]
aft <- (3:d)[parentset == 3]
common_inv <- solve(siginv[c(mid, ord[2], aft), c(mid, ord[2], aft)])
val <- siginv[ord[1], ord[1]] - siginv[ord[1], c(mid, ord[2], aft)] %*% common_inv %*% siginv[c(mid, ord[2], aft), ord[1]] + siginv[ord[2], ord[2]]
if (length(aft) != 0) {
val <- val - siginv[ord[2], aft] %*% solve(siginv[aft, aft]) %*% siginv[aft, ord[2]]
}
# Update the likelihood value based on the ordering
update_val <- function(subset, base_set) {
for (i in seq_along(subset)) {
vord <- c(subset[-(1:i)], base_set)
val <<- val * sqrt(siginv[subset[i], subset[i]]
if(length(vord)!=0) {
#'
#' @param index Integer representing the causal ordering.
#' @param d Number of variables in the system.
#' @param n Sample size.
#' @param siginv Inverse of the covariance matrix.
#' @param tresh Likelihood ratio threshold.
#' @param ord ordering of potential cause and potential effect
#' @param crit Chi-square critical value for hypothesis testing.
#' @return Vector of plausible causal orderings with corresponding likelihood value.
#' @export
orderDualLRTpartial<- function(index, d, n, siginv, tresh, ord, crit) {
# Convert ordering into partition (before cause, between cause and effect, after effect)
parentset <- unname(gtools::baseOf(index, base = 3, len = d - 2) + 1)
pre <- (3:d)[parentset == 1]
mid <- (3:d)[parentset == 2]
aft <- (3:d)[parentset == 3]
common_inv <- solve(siginv[c(mid, ord[2], aft), c(mid, ord[2], aft)])
val <- siginv[ord[1], ord[1]] - siginv[ord[1], c(mid, ord[2], aft)] %*% common_inv %*% siginv[c(mid, ord[2], aft), ord[1]] + siginv[ord[2], ord[2]]
if (length(aft) != 0) {
val <- val - siginv[ord[2], aft] %*% solve(siginv[aft, aft]) %*% siginv[aft, ord[2]]
}
# Update the likelihood value based on the ordering
update_val <- function(subset, base_set) {
for (i in seq_along(subset)) {
vord <- c(subset[-(1:i)], base_set)
val <<- val * sqrt(siginv[subset[i], subset[i]]
if(length(vord)!=0) {
#'
#' @param index Integer representing the causal ordering.
#' @param d Number of variables in the system.
#' @param n Sample size.
#' @param siginv Inverse of the covariance matrix.
#' @param tresh Likelihood ratio threshold.
#' @param ord ordering of potential cause and potential effect
#' @param crit Chi-square critical value for hypothesis testing.
#' @return Vector of plausible causal orderings with corresponding likelihood value.
#' @export
orderDualLRTpartial<- function(index, d, n, siginv, tresh, ord, crit) {
# Convert ordering into partition (before cause, between cause and effect, after effect)
parentset <- unname(gtools::baseOf(index, base = 3, len = d - 2) + 1)
pre <- (3:d)[parentset == 1]
mid <- (3:d)[parentset == 2]
aft <- (3:d)[parentset == 3]
common_inv <- solve(siginv[c(mid, ord[2], aft), c(mid, ord[2], aft)])
val <- siginv[ord[1], ord[1]] - siginv[ord[1], c(mid, ord[2], aft)] %*% common_inv %*% siginv[c(mid, ord[2], aft), ord[1]] + siginv[ord[2], ord[2]]
if (length(aft) != 0) {
val <- val - siginv[ord[2], aft] %*% solve(siginv[aft, aft]) %*% siginv[aft, ord[2]]
}
# Update the likelihood value based on the ordering
update_val <- function(subset, base_set) {
for (i in seq_along(subset)) {
vord <- c(subset[-(1:i)], base_set)
val <<- val * sqrt(siginv[subset[i], subset[i]]  - siginv[subset[i], vord] %*% solve(siginv[vord, vord]) %*% siginv[vord, subset[i]])
if (length(vord)!=0) {
val <<- val * sqrt(siginv[subset[i], subset[i]]  - siginv[subset[i], vord] %*% solve(siginv[vord, vord]) %*% siginv[vord, subset[i]])
} else {
val <<- val * sqrt(siginv[subset[i], subset[i]])
}
}
}
if (length(pre) != 0) update_val(pre, c(ord, mid, aft))
if (length(mid) != 0) update_val(mid, c(ord[2], aft))
if (length(aft) != 0) update_val(aft, NULL)
# test the ordering with dual likelihood ratio test
lik <- -log(val)
if ((tresh - lik) > (crit / (2 * n))) {
return()
}
return(c(pre, ord[1], mid, ord[2], aft, lik))
}
orderfalse <- parallel::mclapply(0:(3^(d - 2) - 1), orderDualLRTpartial, tresh = tresh, d = d, n = n, siginv = siginv, ord = c(2, 1), crit = stats::qchisq(1 - alpha, 1), mc.cores = parallel::detectCores())
# Convert ordering into partition (before cause, between cause and effect, after effect)
parentset <- unname(gtools::baseOf(index, base = 3, len = d - 2) + 1)
pre <- (3:d)[parentset == 1]
mid <- (3:d)[parentset == 2]
aft <- (3:d)[parentset == 3]
common_inv <- solve(siginv[c(mid, ord[2], aft), c(mid, ord[2], aft)])
val <- siginv[ord[1], ord[1]] - siginv[ord[1], c(mid, ord[2], aft)] %*% common_inv %*% siginv[c(mid, ord[2], aft), ord[1]] + siginv[ord[2], ord[2]]
if (length(aft) != 0) {
val <- val - siginv[ord[2], aft] %*% solve(siginv[aft, aft]) %*% siginv[aft, ord[2]]
}
# Update the likelihood value based on the ordering
update_val <- function(subset, base_set) {
for (i in seq_along(subset)) {
vord <- c(subset[-(1:i)], base_set)
val <<- val * sqrt(siginv[subset[i], subset[i]]  - siginv[subset[i], vord] %*% solve(siginv[vord, vord]) %*% siginv[vord, subset[i]])
if (length(vord)!=0) {
val <<- val * sqrt(siginv[subset[i], subset[i]]  - siginv[subset[i], vord] %*% solve(siginv[vord, vord]) %*% siginv[vord, subset[i]])
} else {
val <<- val * sqrt(siginv[subset[i], subset[i]])
}
}
}
if (length(pre) != 0) update_val(pre, c(ord, mid, aft))
if (length(mid) != 0) update_val(mid, c(ord[2], aft))
if (length(aft) != 0) update_val(aft, NULL)
# test the ordering with dual likelihood ratio test
lik <- -log(val)
if ((tresh - lik) > (crit / (2 * n))) {
return()
}
index=7
# Convert ordering into partition (before cause, between cause and effect, after effect)
parentset <- unname(gtools::baseOf(index, base = 3, len = d - 2) + 1)
pre <- (3:d)[parentset == 1]
mid <- (3:d)[parentset == 2]
aft <- (3:d)[parentset == 3]
common_inv <- solve(siginv[c(mid, ord[2], aft), c(mid, ord[2], aft)])
val <- siginv[ord[1], ord[1]] - siginv[ord[1], c(mid, ord[2], aft)] %*% common_inv %*% siginv[c(mid, ord[2], aft), ord[1]] + siginv[ord[2], ord[2]]
if (length(aft) != 0) {
val <- val - siginv[ord[2], aft] %*% solve(siginv[aft, aft]) %*% siginv[aft, ord[2]]
}
# Update the likelihood value based on the ordering
update_val <- function(subset, base_set) {
for (i in seq_along(subset)) {
vord <- c(subset[-(1:i)], base_set)
val <<- val * sqrt(siginv[subset[i], subset[i]]  - siginv[subset[i], vord] %*% solve(siginv[vord, vord]) %*% siginv[vord, subset[i]])
if (length(vord)!=0) {
val <<- val * sqrt(siginv[subset[i], subset[i]]  - siginv[subset[i], vord] %*% solve(siginv[vord, vord]) %*% siginv[vord, subset[i]])
} else {
val <<- val * sqrt(siginv[subset[i], subset[i]])
}
}
}
if (length(pre) != 0) update_val(pre, c(ord, mid, aft))
if (length(mid) != 0) update_val(mid, c(ord[2], aft))
if (length(aft) != 0) update_val(aft, NULL)
subset=aft
i=9
vord <- c(subset[-(1:i)], base_set)
base_set=NULL
vord <- c(subset[-(1:i)], base_set)
vord <- c(subset[-(1:i)], base_set)
if (length(vord)!=0) {
val <<- val * sqrt(siginv[subset[i], subset[i]]  - siginv[subset[i], vord] %*% solve(siginv[vord, vord]) %*% siginv[vord, subset[i]])
} else {
val <<- val * sqrt(siginv[subset[i], subset[i]])
}
#'
#' @param index Integer representing the causal ordering.
#' @param d Number of variables in the system.
#' @param n Sample size.
#' @param siginv Inverse of the covariance matrix.
#' @param tresh Likelihood ratio threshold.
#' @param ord ordering of potential cause and potential effect
#' @param crit Chi-square critical value for hypothesis testing.
#' @return Vector of plausible causal orderings with corresponding likelihood value.
#' @export
orderDualLRTpartial<- function(index, d, n, siginv, tresh, ord, crit) {
# Convert ordering into partition (before cause, between cause and effect, after effect)
parentset <- unname(gtools::baseOf(index, base = 3, len = d - 2) + 1)
pre <- (3:d)[parentset == 1]
mid <- (3:d)[parentset == 2]
aft <- (3:d)[parentset == 3]
common_inv <- solve(siginv[c(mid, ord[2], aft), c(mid, ord[2], aft)])
val <- siginv[ord[1], ord[1]] - siginv[ord[1], c(mid, ord[2], aft)] %*% common_inv %*% siginv[c(mid, ord[2], aft), ord[1]] + siginv[ord[2], ord[2]]
if (length(aft) != 0) {
val <- val - siginv[ord[2], aft] %*% solve(siginv[aft, aft]) %*% siginv[aft, ord[2]]
}
# Update the likelihood value based on the ordering
update_val <- function(subset, base_set) {
for (i in seq_along(subset)) {
vord <- c(subset[-(1:i)], base_set)
if (length(vord)!=0) {
val <<- val * sqrt(siginv[subset[i], subset[i]]  - siginv[subset[i], vord] %*% solve(siginv[vord, vord]) %*% siginv[vord, subset[i]])
} else {
val <<- val * sqrt(siginv[subset[i], subset[i]])
}
}
}
if (length(pre) != 0) update_val(pre, c(ord, mid, aft))
if (length(mid) != 0) update_val(mid, c(ord[2], aft))
if (length(aft) != 0) update_val(aft, NULL)
# test the ordering with dual likelihood ratio test
lik <- -log(val)
if ((tresh - lik) > (crit / (2 * n))) {
return()
}
return(c(pre, ord[1], mid, ord[2], aft, lik))
}
orderfalse <- parallel::mclapply(0:(3^(d - 2) - 1), orderDualLRTpartial, tresh = tresh, d = d, n = n, siginv = siginv, ord = c(2, 1), crit = stats::qchisq(1 - alpha, 1), mc.cores = parallel::detectCores())
# Find plausible causal orderings (parallelized)
ordertrue <- parallel::mclapply(0:(3^(d - 2) - 1), orderDualLRTpartial, tresh = tresh, d = d, n = n, siginv = siginv, ord = c(1, 2), crit = stats::qchisq(1 - alpha, 2), mc.cores = parallel::detectCores())
ordertrue <- do.call(rbind, ordertrue)
orderfalse <- parallel::mclapply(0:(3^(d - 2) - 1), orderDualLRTpartial, tresh = tresh, d = d, n = n, siginv = siginv, ord = c(2, 1), crit = stats::qchisq(1 - alpha, 1), mc.cores = parallel::detectCores())
orderfalse <- do.call(rbind, orderfalse)
# Find MLE and test for zero effect
L1 <- max(c(ordertrue[, d + 1], orderfalse[, d + 1]))
zeropossible <- if (!is.null(orderfalse)) (L1 - max(orderfalse[, d + 1]) <= stats::qchisq(1 - alpha, 1) / (2 * n)) else FALSE
# Reduce set of plausible orderings using true MLE
if (!is.null(ordertrue)) {
ind <- (L1 - ordertrue[, d + 1]) <= (stats::qchisq(1 - alpha, 2) / (2 * n))
ordertrue <- ordertrue[ind, , drop = FALSE]
}
# If no plausible orderings, return NA otherwise test within intervals for effect
if (nrow(ordertrue) == 0) {
return(c(zeropossible, NA, NA))
} else {
intervals <- intervalsDualLRTpartial(siginv, ordertrue[, 1:d, drop = FALSE], L1, alpha, d, n)
return(c(zeropossible, intervals))
}
intervals
